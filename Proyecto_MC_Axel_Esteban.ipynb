{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto_MC_Axel_Esteban.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIsMVv-d1-qz"
      },
      "source": [
        "# Esquema de Aprendizaje Basado en la Ecuación HJB para redes Neuronales Artificiales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRjxPPAc14P8"
      },
      "source": [
        "# Librerías\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "import time as time\n",
        "import numpy as np"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vny2H5sr2KrC"
      },
      "source": [
        "# Parámetros\n",
        "batch_size          = 64\n",
        "shuffle_buffer_size = 100\n",
        "training_epochs     = 10"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biaCUSFi2VxQ"
      },
      "source": [
        "num_classes                   = 10\n",
        "img_rows, img_cols, channels  = 28, 28, 1"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSwHSbnb2bXi"
      },
      "source": [
        "# Cargo Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCXtgVOt2cVr",
        "outputId": "dc37ceb8-d6fb-476b-cdcd-ed37218f089f"
      },
      "source": [
        "# Utilizo datos MNIST para prueba \n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Expando dimensiones\n",
        "x_train = np.expand_dims(x_train, 3)\n",
        "x_test  = np.expand_dims(x_test, 3)\n",
        "\n",
        "# Normalizo\n",
        "x_train = x_train.astype(np.float32) /255.\n",
        "x_test  = x_test.astype(np.float32) / 255.\n",
        "\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_train.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  (60000, 28, 28, 1)\n",
            "x_test shape:  (60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9_3PH2m6N_w"
      },
      "source": [
        "# Vectorizo resultados\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "# Transformo a tensores\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "# Elijo de manera aleatoria\n",
        "train_ds = train_ds.shuffle(shuffle_buffer_size).batch(batch_size)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_ds = test_ds.batch(batch_size)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjsY5RqZ3Fpt"
      },
      "source": [
        "# Defino modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArnBrKa33HAF"
      },
      "source": [
        "def get_model():\n",
        "  model = Sequential()\n",
        "  model.add(layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                     activation='relu',\n",
        "                     input_shape = input_shape))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation = 'relu'))\n",
        "  model.add(layers.Dense(num_classes, activation = 'softmax'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mFWdgd2-6Sn"
      },
      "source": [
        "def hjb_optimize(model, train_ds, test_ds, r=100., epochs=6, metric=tf.keras.metrics.Accuracy):\n",
        "    train_loss_results = []\n",
        "    train_accuracy_results = []\n",
        "\n",
        "    star = time.time() \n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "        epoch_accuracy = metric()\n",
        "        # Obtengo gradientes\n",
        "        for x, y in train_ds:\n",
        "            grads  = mse_grad(model, x, y)\n",
        "            grad_t = None\n",
        "            for g in grads:\n",
        "                if grad_t is None:\n",
        "                    grad_t = tf.reshape(g, [-1])\n",
        "                else:\n",
        "                    grad_t = tf.concat([grad_t, tf.reshape(g, [-1])], 0)\n",
        "            # Obtengo actualización\n",
        "            grad_norm_value = tf.norm(grad_t)\n",
        "            loss_value = model.loss(y_true = y, y_pred = model(x, training=True))\n",
        "            grad_t *= tf.sqrt(2*loss_value)\n",
        "            grad_t /= grad_norm_value\n",
        "            grad_t /= tf.sqrt(r)\n",
        "            # Actualizo gradientes\n",
        "            it = 0\n",
        "            for g in grads:\n",
        "                len_g = np.prod(g.shape)\n",
        "                g = tf.reshape(grad_t[it:it+len_g], g.shape)\n",
        "                it += len_g\n",
        "            (model.optimizer).apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "            # Guardo Resultados\n",
        "            epoch_loss_avg.update_state(loss_value)\n",
        "            epoch_accuracy.update_state(y, model(x, training=True))\n",
        "\n",
        "        # End epoch\n",
        "        train_loss_results.append(epoch_loss_avg.result())\n",
        "        train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "        print(\"Epoch {:01d}/{:02d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch+1, epochs,\n",
        "                                                                    epoch_loss_avg.result(),\n",
        "                                                                    epoch_accuracy.result()))\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    print('Training time: ', time.time()- star, 'seconds.')\n",
        "    \n",
        "    test_accuracy = metric()   \n",
        "    star = time.time()\n",
        "    for x, y in test_ds:\n",
        "        test_accuracy.update_state(y, model(x, training=False))\n",
        "    print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fEsSP9K3Q1i"
      },
      "source": [
        "# Defino función de error\n",
        "def mse_grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = tf.keras.losses.mean_squared_error(y_true=targets, y_pred=model(inputs, training=True))\n",
        "  return tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc6DjOvu3V-e"
      },
      "source": [
        "# Entrenamiento HJB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eEgN3aW5ADz",
        "outputId": "a638fdba-f04d-47c1-c06d-1de20c8a0789"
      },
      "source": [
        "model = get_model()\n",
        "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(), optimizer = tf.keras.optimizers.Adagrad())\n",
        "hjb_optimize(model, train_ds, test_ds, r = 100., epochs = training_epochs, metric = tf.keras.metrics.CategoricalAccuracy)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 01/10: Loss: 0.709, Accuracy: 83.040%\n",
            "Epoch 02/10: Loss: 0.294, Accuracy: 93.765%\n",
            "Epoch 03/10: Loss: 0.251, Accuracy: 94.835%\n",
            "Epoch 04/10: Loss: 0.222, Accuracy: 95.425%\n",
            "Epoch 05/10: Loss: 0.201, Accuracy: 95.892%\n",
            "Epoch 06/10: Loss: 0.184, Accuracy: 96.267%\n",
            "Epoch 07/10: Loss: 0.171, Accuracy: 96.572%\n",
            "Epoch 08/10: Loss: 0.159, Accuracy: 96.847%\n",
            "Epoch 09/10: Loss: 0.149, Accuracy: 97.068%\n",
            "Epoch 10/10: Loss: 0.140, Accuracy: 97.325%\n",
            "Training time:  165.99798226356506 seconds.\n",
            "Test set accuracy: 96.580%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Hkkwxs5IhT"
      },
      "source": [
        "# Adagrad Estándar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HuI8xTr5LGF",
        "outputId": "e59f14c0-86b1-4fee-8d7c-fe010a824a45"
      },
      "source": [
        "model = get_model()\n",
        "model.compile(loss      = tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer = tf.keras.optimizers.Adagrad(),\n",
        "              metrics   = ['accuracy'])\n",
        "\n",
        "star = time.time()\n",
        "model.fit(train_ds, \n",
        "          epochs = training_epochs)\n",
        "print ('Training time :', time.time() - star, 'seconds')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7055 - accuracy: 0.5844\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.3662 - accuracy: 0.8964\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2966 - accuracy: 0.9157\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2616 - accuracy: 0.9260\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2363 - accuracy: 0.9321\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2170 - accuracy: 0.9374\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2011 - accuracy: 0.9418\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1879 - accuracy: 0.9462\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.1756 - accuracy: 0.9499\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1665 - accuracy: 0.9525\n",
            "Training time : 46.8939471244812 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQPN_U8k-idZ",
        "outputId": "9b652d39-d9d3-47a1-c74d-16a30a8756de"
      },
      "source": [
        "# Validación\n",
        "star  = time.time()\n",
        "score = model.evaluate(test_ds)\n",
        "print('Test accuracy:', score[1])\n",
        "print ('Testing time :', time.time() - star, 'seconds.')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 1s 3ms/step - loss: 0.1592 - accuracy: 0.9543\n",
            "Test accuracy: 0.9542999863624573\n",
            "Testing time : 0.6389431953430176 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPoncIqK80rK"
      },
      "source": [
        "# SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXqm-0hW80Js",
        "outputId": "cde825a2-0d51-4c34-b530-bf708ccf6507"
      },
      "source": [
        "model = get_model()\n",
        "model.compile(loss      = tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum = 0.9, nesterov = True),\n",
        "              metrics   = ['accuracy'])\n",
        "star = time.time()\n",
        "model.fit(train_ds, \n",
        "          epochs = training_epochs)\n",
        "print ('Training time :', time.time() - star, 'seconds.')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.4747 - accuracy: 0.8605\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0805 - accuracy: 0.9762\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0489 - accuracy: 0.9857\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0320 - accuracy: 0.9902\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0228 - accuracy: 0.9933\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0161 - accuracy: 0.9950\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0123 - accuracy: 0.9967\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0098 - accuracy: 0.9972\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0069 - accuracy: 0.9980\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0050 - accuracy: 0.9988\n",
            "Training time : 46.94995069503784 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv6oSuJp9aeg",
        "outputId": "9e6834c4-249d-4b8a-e1ce-530d3c0aee93"
      },
      "source": [
        "# Validación\n",
        "star  = time.time()\n",
        "score = model.evaluate(test_ds)\n",
        "print('Test accuracy:', score[1])\n",
        "print ('Testing time :', time.time() - star, 'seconds.')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.9887\n",
            "Test accuracy: 0.9886999726295471\n",
            "Testing time : 0.6290290355682373 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoJ8NLCoFItl"
      },
      "source": [
        "Revisar\n",
        "1. Usar el test set en cada iteración para no sobrentrenar.\n",
        "2. Graficar pérdida y accuracy.\n",
        "3. Revisar eficiencia del HJB comparado con los otros métodos.\n"
      ]
    }
  ]
}